{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generates daily matrices with mobility adjusted commuter flows\n",
    "Output: Pickle file (dictionary of sparce matrices, by date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "import re, pickle,copy, scipy\n",
    "from datetime import datetime, timedelta\n",
    "from scipy.sparse import csr_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3142\n"
     ]
    }
   ],
   "source": [
    "# FIPS information\n",
    "fips = pd.read_excel('fips_data.xlsx')[1:]\n",
    "fips['lat'] = fips.apply(lambda x: float(re.sub('–','-',str(x['Latitude'])[:-1])),axis=1)\n",
    "fips['lon'] = fips.apply(lambda x: float(re.sub('–','-',str(x['Longitude'])[:-1])),axis=1)\n",
    "fips['fips'] = fips['FIPS']\n",
    "\n",
    "# state name to abbreviation\n",
    "statecode = pd.read_csv('statecode.csv')\n",
    "statecode.columns = ['name','State']\n",
    "fips = pd.merge(fips,statecode,on='State')\n",
    "fips.head()\n",
    "\n",
    "# selecting USA mobility reports\n",
    "gmr = pd.read_csv('Global_Mobility_Report.csv')\n",
    "mr = gmr[gmr['country_region_code']=='US'].copy()\n",
    "del gmr\n",
    "mr['datetime'] = mr.apply(lambda x: datetime.strptime(x['date'],'%Y-%m-%d'),axis=1)\n",
    "\n",
    "# importing flows data\n",
    "flow = pickle.load(open('flow.pickle', 'rb'))\n",
    "all_fips = [x for x in sorted(set(flow['sfips'])) if x//1000 != 72]\n",
    "print(len(all_fips))\n",
    "\n",
    "# selecting statewide data\n",
    "statemr = mr[mr['sub_region_2'].isnull()].fillna('NA')\n",
    "statemr['unique'] = statemr.apply(lambda x: '%s_%s' %(str(x['sub_region_1']),str(x['datetime'])),axis=1)\n",
    "statemr = statemr.set_index('unique')['workplaces_percent_change_from_baseline'].to_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating DataFrame\n",
    "mobility_work = pd.DataFrame()\n",
    "mobility_work['fips'] = all_fips\n",
    "\n",
    "\n",
    "# merging with state name\n",
    "mobility_work = pd.merge(mobility_work,fips[['fips','name']],how='left',on='fips')\n",
    "mobility_work.columns = ['fips','state']\n",
    "\n",
    "# cleaning\n",
    "mobility_work = mobility_work.fillna('NA')\n",
    "mobility_work = mobility_work.replace(to_replace ='Dist. of Columbia', \n",
    "                 value ='NA') \n",
    "\n",
    "\n",
    "# creating baseline statelevel mobility metrics\n",
    "for date in set(mr['datetime']):\n",
    "    date = str(date)\n",
    "    mobility_work[date] = mobility_work.swifter.progress_bar(False).apply(lambda x: statemr['%s_%s' %(str(x['state']),date)],axis=1)\n",
    "\n",
    "# converting to dicitonary\n",
    "state_work = mobility_work.set_index('fips').to_dict('index')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matching county names to FIPS codes and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kellen\\Anaconda\\envs\\kellen\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n",
      "C:\\Users\\Kellen\\Anaconda\\envs\\kellen\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\Kellen\\Anaconda\\envs\\kellen\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "to_concat = []\n",
    "states = mr.groupby('sub_region_1')\n",
    "for state, group in states:\n",
    "    state_fips = fips[fips['name']==state][['FIPS','County\\xa0[2]','name']]\n",
    "    try:\n",
    "        state_fips.columns = ['fips','county','state_name']\n",
    "        group['county'] = group.apply(lambda x: re.sub(' County','',str(x['sub_region_2'])),axis=1)\n",
    "        group['county'] = group.apply(lambda x: re.findall(re.compile('[\\w\\. ]+'),str(x['county']))[0],axis=1)\n",
    "        group['county'] = group.apply(lambda x: re.sub(' Parish','',str(x['county'])),axis=1)\n",
    "        state_fips['county'] = state_fips.apply(lambda x: re.sub(' Parish','',str(x['county'])),axis=1)\n",
    "        state_fips['county'] = state_fips.apply(lambda x: re.findall(re.compile('[\\w\\. ]+'),str(x['county']))[0],axis=1)\n",
    "        df = pd.merge(group,state_fips,how='right',on='county')\n",
    "        to_concat.append(df)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "mobility = pd.concat(to_concat)\n",
    "mobility = mobility[~mobility['date'].isnull()].copy()\n",
    "mobility['datetime'] = mobility.apply(lambda x: datetime.strptime(x['date'],'%Y-%m-%d'),axis=1)\n",
    "mobility = mobility[['sub_region_1','workplaces_percent_change_from_baseline','fips','datetime']].dropna(axis=0)\n",
    "\n",
    "fips_mobility = copy.deepcopy(state_work)\n",
    "for index,row in mobility.iterrows():\n",
    "    if row['fips'] in state_work:\n",
    "        if state_work[row['fips']]['state'] == row['sub_region_1']:\n",
    "            fips_mobility[row['fips']][str(row['datetime'])] = row['workplaces_percent_change_from_baseline']\n",
    "            \n",
    "mobility_df = pd.DataFrame(fips_mobility).transpose()\n",
    "mobility_df = mobility_df.drop('state',axis=1)\n",
    "\n",
    "# remove any fips starting with 72\n",
    "flow = flow[(flow['sfips']//1000 != 72)&(flow['efips']//1000 != 72)]\n",
    "all_fips = sorted(set(flow['sfips']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow['identical'] = flow.apply(lambda x: 1 if x['sfips']==x['efips'] else 0,axis=1)\n",
    "fipindex = pd.Series({x:all_fips.index(x) for x in all_fips})\n",
    "\n",
    "def create_commuting_matrix(df,scores,date):\n",
    "    #df['mobility_score'] = scores[date][np.array(df['sfips'])].values\n",
    "    df['mobility_score'] = scores[str(date)][np.array(df['sfips'])].values\n",
    "    \n",
    "    # for different counties\n",
    "    df['weight'] = (1-df['identical'].values)*(df['commuter%'].values*(1+df['mobility_score'].values/100))\n",
    "    \n",
    "    # for within county\n",
    "    df['weight'] = df['weight'].values + (df['identical'].values)*(df['commuter%'].values - (1-df['commuter%'].values)*(df['mobility_score']/100))\n",
    "    df = df[['sfips','efips','weight','mobility_score']].copy()\n",
    "    \n",
    "    M = np.zeros((len(fipindex),len(fipindex)))\n",
    "    M[fipindex[df['efips'].values].values,fipindex[df['sfips'].values].values] = df['weight'].values\n",
    "    return(scipy.sparse.csr_matrix(M))\n",
    "\n",
    "dates = sorted(set(mr['datetime']))\n",
    "date_conversion = {x:x for x in dates}\n",
    "date = dates[-1]\n",
    "all_dates = dates.copy()\n",
    "\n",
    "#Redundant - execute in other notebooks\n",
    "'''while date <= datetime(2020,4,29):\n",
    "    date = date + timedelta(days=1)\n",
    "    date_conversion[date] = dates[-1]\n",
    "    all_dates.append(date)'''\n",
    "    \n",
    "matrices = {}\n",
    "for date in all_dates:\n",
    "    matrices[date] = create_commuting_matrix(flow,mobility_df,date_conversion[date])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Timestamp('2020-02-15 00:00:00'),\n",
       " Timestamp('2020-02-16 00:00:00'),\n",
       " Timestamp('2020-02-17 00:00:00'),\n",
       " Timestamp('2020-02-18 00:00:00'),\n",
       " Timestamp('2020-02-19 00:00:00'),\n",
       " Timestamp('2020-02-20 00:00:00'),\n",
       " Timestamp('2020-02-21 00:00:00'),\n",
       " Timestamp('2020-02-22 00:00:00'),\n",
       " Timestamp('2020-02-23 00:00:00'),\n",
       " Timestamp('2020-02-24 00:00:00'),\n",
       " Timestamp('2020-02-25 00:00:00'),\n",
       " Timestamp('2020-02-26 00:00:00'),\n",
       " Timestamp('2020-02-27 00:00:00'),\n",
       " Timestamp('2020-02-28 00:00:00'),\n",
       " Timestamp('2020-02-29 00:00:00'),\n",
       " Timestamp('2020-03-01 00:00:00'),\n",
       " Timestamp('2020-03-02 00:00:00'),\n",
       " Timestamp('2020-03-03 00:00:00'),\n",
       " Timestamp('2020-03-04 00:00:00'),\n",
       " Timestamp('2020-03-05 00:00:00'),\n",
       " Timestamp('2020-03-06 00:00:00'),\n",
       " Timestamp('2020-03-07 00:00:00'),\n",
       " Timestamp('2020-03-08 00:00:00'),\n",
       " Timestamp('2020-03-09 00:00:00'),\n",
       " Timestamp('2020-03-10 00:00:00'),\n",
       " Timestamp('2020-03-11 00:00:00'),\n",
       " Timestamp('2020-03-12 00:00:00'),\n",
       " Timestamp('2020-03-13 00:00:00'),\n",
       " Timestamp('2020-03-14 00:00:00'),\n",
       " Timestamp('2020-03-15 00:00:00'),\n",
       " Timestamp('2020-03-16 00:00:00'),\n",
       " Timestamp('2020-03-17 00:00:00'),\n",
       " Timestamp('2020-03-18 00:00:00'),\n",
       " Timestamp('2020-03-19 00:00:00'),\n",
       " Timestamp('2020-03-20 00:00:00'),\n",
       " Timestamp('2020-03-21 00:00:00'),\n",
       " Timestamp('2020-03-22 00:00:00'),\n",
       " Timestamp('2020-03-23 00:00:00'),\n",
       " Timestamp('2020-03-24 00:00:00'),\n",
       " Timestamp('2020-03-25 00:00:00'),\n",
       " Timestamp('2020-03-26 00:00:00'),\n",
       " Timestamp('2020-03-27 00:00:00'),\n",
       " Timestamp('2020-03-28 00:00:00'),\n",
       " Timestamp('2020-03-29 00:00:00'),\n",
       " Timestamp('2020-03-30 00:00:00'),\n",
       " Timestamp('2020-03-31 00:00:00'),\n",
       " Timestamp('2020-04-01 00:00:00'),\n",
       " Timestamp('2020-04-02 00:00:00'),\n",
       " Timestamp('2020-04-03 00:00:00'),\n",
       " Timestamp('2020-04-04 00:00:00'),\n",
       " Timestamp('2020-04-05 00:00:00'),\n",
       " Timestamp('2020-04-06 00:00:00'),\n",
       " Timestamp('2020-04-07 00:00:00'),\n",
       " Timestamp('2020-04-08 00:00:00'),\n",
       " Timestamp('2020-04-09 00:00:00'),\n",
       " Timestamp('2020-04-10 00:00:00'),\n",
       " Timestamp('2020-04-11 00:00:00'),\n",
       " Timestamp('2020-04-12 00:00:00'),\n",
       " Timestamp('2020-04-13 00:00:00'),\n",
       " Timestamp('2020-04-14 00:00:00'),\n",
       " Timestamp('2020-04-15 00:00:00'),\n",
       " Timestamp('2020-04-16 00:00:00'),\n",
       " Timestamp('2020-04-17 00:00:00'),\n",
       " Timestamp('2020-04-18 00:00:00'),\n",
       " Timestamp('2020-04-19 00:00:00'),\n",
       " Timestamp('2020-04-20 00:00:00'),\n",
       " Timestamp('2020-04-21 00:00:00'),\n",
       " Timestamp('2020-04-22 00:00:00'),\n",
       " Timestamp('2020-04-23 00:00:00'),\n",
       " Timestamp('2020-04-24 00:00:00'),\n",
       " Timestamp('2020-04-25 00:00:00'),\n",
       " Timestamp('2020-04-26 00:00:00')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(matrices,open('matrices.pickle','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
