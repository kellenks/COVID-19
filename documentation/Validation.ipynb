{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, matplotlib.pyplot as plt\n",
    "import re, pickle\n",
    "from datetime import datetime\n",
    "import scipy, itertools\n",
    "import scipy.stats\n",
    "#For random forest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score, roc_curve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "t14_cases = pickle.load(open('estimates.pickle','rb'))['t14_cases']\n",
    "t14_recovered = pickle.load(open('estimates.pickle','rb'))['t14_recovered']\n",
    "estimated_cases = pickle.load(open('estimates.pickle','rb'))['estimated_cases']\n",
    "estimated_recovered = pickle.load(open('estimates.pickle','rb'))['estimated_recovered']\n",
    "cases_added = pickle.load(open('time_series.pickle','rb'))['cases_added'].loc[estimated_cases.index]\n",
    "cases_full = pickle.load(open('time_series.pickle','rb'))['cases_full'].loc[estimated_cases.index]\n",
    "ecbd = pickle.load(open('time_series.pickle','rb'))['ECBD'].loc[estimated_cases.index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fips = pd.read_excel('fips_data.xlsx')[1:]\n",
    "fips['lat'] = fips.apply(lambda x: float(re.sub('–','-',str(x['Latitude'])[:-1])),axis=1)\n",
    "fips['lon'] = fips.apply(lambda x: float(re.sub('–','-',str(x['Longitude'])[:-1])),axis=1)\n",
    "fips['index'] = fips['FIPS']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing = pd.read_csv('states_daily_4pm_et.csv')\n",
    "testing['datetime'] = testing.apply(lambda x: datetime.strptime(str(x['date']),'%Y%m%d'),axis=1)\n",
    "testing['number_of_tests'] = testing['positive']+testing['negative']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = list(estimated_cases)[-1]\n",
    "merged = pd.merge(estimated_cases[[date]].reset_index(),estimated_recovered[[date]].reset_index(),on='index').set_index('index')\n",
    "merged['total'] = merged.sum(axis=1)\n",
    "merged = pd.merge(merged.reset_index(),fips[['index','County\\xa0[2]','Land Area','State']],how='left',on='index').set_index('index')\n",
    "merged = pd.merge(merged.reset_index(),cases_added[[date]].set_index(pd.Index(cases_full.index.values)).reset_index(),how='left',on='index')\n",
    "merged = merged[['index','total','County\\xa0[2]','State',date]].reset_index(drop=True)\n",
    "merged.columns = ['FIPS','Estimated','County','State','Reported']\n",
    "merged = merged[['FIPS','State','County','Reported','Estimated']].sort_values(by='Estimated',ascending=False)\n",
    "merged['Estimated'] = merged['Estimated'].astype(int)\n",
    "merged.head(12)\n",
    "\n",
    "ecbd = ecbd*(100/1.38)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_to_merge = testing[['datetime','state','number_of_tests']]\n",
    "testing_to_merge.columns = ['level_0','State','tests']\n",
    "\n",
    "features = pd.merge(estimated_cases.transpose().stack().reset_index(),estimated_recovered.transpose().stack().reset_index(),on=['level_0','level_1'])\n",
    "features.columns = ['level_0','FIPS','ecases','erecovered']\n",
    "features = pd.merge(features,ecbd.transpose().stack().reset_index(),how='left',on=['level_0','FIPS'])\n",
    "features = pd.merge(cases_full.transpose().stack().reset_index(),features,on=['level_0','FIPS'])\n",
    "features = pd.merge(features,fips[['FIPS','State','Population']],how='left',on='FIPS') \n",
    "features = pd.merge(features,testing_to_merge,how='left',on=['level_0','State']).fillna(0)\n",
    "\n",
    "features['estimated'] = features['ecases']#+features['erecovered']\n",
    "features = features.drop(['FIPS','ecases','erecovered'],axis=1)\n",
    "features.columns = ['date','r','fdce','state','p','t','estimated']\n",
    "\n",
    "features = features.groupby(['date','state']).sum().reset_index()\n",
    "features = features[features['state'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['label'] = features['r']/(features['t'])\n",
    "features['e0'] = features['r']\n",
    "features['e1'] = features['fdce']\n",
    "features['e2'] = features['estimated']\n",
    "features['rp'] = features['r']/features['p']\n",
    "features['re0'] = features['r']/features['e0']\n",
    "features['re1'] = features['r']/features['e1']\n",
    "features['re2'] = features['r']/features['e2']\n",
    "features['e0p'] = features['e0']/features['p']\n",
    "features['e1p'] = features['e1']/features['p']\n",
    "features['e2p'] = features['e2']/features['p']\n",
    "\n",
    "features = features.replace([-np.inf,np.inf], np.nan)\n",
    "features = features.fillna(0)\n",
    "features_store = features.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ID']\n",
      "['ME']\n",
      "['RI']\n",
      "['CO']\n",
      "['KY']\n",
      "['CT']\n",
      "['MI']\n",
      "['PA']\n",
      "['TN']\n",
      "['WV']\n",
      "['AZ']\n",
      "['IA']\n",
      "['IN']\n",
      "['DC']\n",
      "['GA']\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "E0 = []\n",
    "E1 = []\n",
    "E2 = []\n",
    "\n",
    "for s in set(features['state']):\n",
    "    \n",
    "    to_test = [s]\n",
    "    print(to_test)\n",
    "    train = features[~features['state'].isin(to_test)][['p','r','e0','rp','re0','e0p','label']]\n",
    "    train = train[features['date'].isin(list(ecbd))]\n",
    "    train_labels = train.pop('label')\n",
    "    test = features[features['state'].isin(to_test)][['p','r','e0','rp','re0','e0p','label']]\n",
    "    test = test[features['date'].isin(list(ecbd))]\n",
    "    test_labels = test.pop('label')\n",
    "\n",
    "    regressor = RandomForestRegressor(max_depth = 5,n_estimators= 100, random_state = 1, criterion = 'mae',bootstrap=True,n_jobs=-1,max_features='auto')\n",
    "\n",
    "    X = np.array(train)\n",
    "\n",
    "    regress = regressor.fit(X,train_labels.values)\n",
    "    \n",
    "    predictions0 = regress.predict(np.array(test))\n",
    "    lineregress_test = scipy.stats.linregress(predictions0,test_labels)\n",
    "    E0.append(lineregress_test[2])\n",
    "    \n",
    "    \n",
    "    #################################################### NEW RF MODEL WITH E1\n",
    "    \n",
    "    train = features[~features['state'].isin(to_test)][['p','r','e1','rp','re1','e1p','label']]\n",
    "    train = train[features['date'].isin(list(ecbd))]\n",
    "    train_labels = train.pop('label')\n",
    "\n",
    "    test = features[features['state'].isin(to_test)][['p','r','e1','rp','re1','e1p','label']]\n",
    "    test = test[features['date'].isin(list(ecbd))]\n",
    "    test_labels = test.pop('label')\n",
    "\n",
    "    regressor = RandomForestRegressor(max_depth = 5,n_estimators= 100, random_state = 1, criterion = 'mae',bootstrap=True,n_jobs=-1,max_features='auto')\n",
    "\n",
    "    X = np.array(train)\n",
    "\n",
    "    regress = regressor.fit(X,train_labels)\n",
    "    \n",
    "    predictions1 = regress.predict(np.array(test))\n",
    "    lineregress_test = scipy.stats.linregress(predictions1,test_labels)\n",
    "    E1.append(lineregress_test[2])\n",
    "    \n",
    "    ################################################## NEW RF MODEL WITH E2\n",
    "    \n",
    "    train = features[~features['state'].isin(to_test)][['p','r','e2','rp','re2','e2p','label']]\n",
    "    train = train[features['date'].isin(list(ecbd))]\n",
    "    train_labels = train.pop('label')\n",
    "\n",
    "    test = features[features['state'].isin(to_test)][['p','r','e2','rp','re2','e2p','label']]\n",
    "    test = test[features['date'].isin(list(ecbd))]\n",
    "    test_labels = test.pop('label')\n",
    "\n",
    "    regressor = RandomForestRegressor(max_depth = 5,n_estimators= 100, random_state = 1, criterion = 'mae',bootstrap=True,n_jobs=-1,max_features='auto')\n",
    "\n",
    "    X = np.array(train)\n",
    "\n",
    "    regress = regressor.fit(X,train_labels)\n",
    "    \n",
    "    predictions2 = regress.predict(np.array(test))\n",
    "    lineregress_test = scipy.stats.linregress(predictions2,test_labels)\n",
    "    E2.append(lineregress_test[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_values = pd.DataFrame()\n",
    "compare_values['E2'] = [x**2 for x in E2]\n",
    "compare_values['E1'] = [x**2 for x in E1]\n",
    "compare_values['E0'] = [x**2 for x in E0]\n",
    "\n",
    "for triple in itertools.permutations(['E2','E1','E0']):\n",
    "    total = compare_values.apply(lambda x: 1 if x[triple[0]] >=  x[triple[1]] >= x[triple[2]] else 0,axis=1).sum()\n",
    "    print(triple,total)\n",
    "\n",
    "compare_values['sig'] = compare_values.apply(lambda x: 1 if max(x['E2'],x['E1'],x['E0']) >= .25  else 0,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('fivethirtyeight')\n",
    "plt.figure(figsize=(12,6))\n",
    "sequence1 = np.array([30,30,28,26,28,26])*.8\n",
    "sequence2 = np.array([28,26,30,30,26,28])*.8\n",
    "sequence3 = np.array([26,28,26,28,30,30])*.8\n",
    "\n",
    "plt.scatter([0,1,2,3,4,5],sequence3,marker='H',s=[200*(x-19) for x in sequence3],color='orange',alpha=.75,label='E0')\n",
    "plt.scatter([0,1,2,3,4,5],sequence2,marker='H',s=[200*(x-19) for x in sequence2],color='red',alpha=.8,label='E1')\n",
    "plt.scatter([0,1,2,3,4,5],sequence1,marker='H',s=[200*(x-19) for x in sequence1],color='black',label='E2')\n",
    "\n",
    "vals = []\n",
    "for triple in itertools.permutations(['E2','E1','E0']):\n",
    "    total = compare_values.apply(lambda x: 1 if x[triple[0]] >=  x[triple[1]] >= x[triple[2]] else 0,axis=1).sum()\n",
    "    compare_values[triple] = compare_values.apply(lambda x: 1 if x[triple[0]] >=  x[triple[1]] >= x[triple[2]] else 0,axis=1)\n",
    "    vals.append(total)\n",
    "\n",
    "\n",
    "plt.bar([0,1,2,3,4,5],[26 for i in range(6)],alpha=.075,color='gray')\n",
    "plt.plot([-.6,5.6],[8.5,8.5],color=(.1,.1,.1),alpha=.9,linestyle='dashed')\n",
    "plt.bar([0,1,2,3,4,5],compare_values.sum()[3:-1].values,color=(.1,.1,.15),alpha=.75)\n",
    "plt.grid(False)\n",
    "plt.xticks([0,1,2,3,4,5,7],['E: 2>1>0','E: 2>0>1','E: 1>2>0','E: 1>0>2','E: 0>2>1','E: 0>1>2',''])\n",
    "plt.yticks([0,5,10,15,20])\n",
    "plt.legend(loc='center right',prop={'size': 15})\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('fivethirtyeight')\n",
    "plt.figure(figsize=(12,6))\n",
    "sequence1 = np.array([30,30,28,26,28,26])*.8\n",
    "sequence2 = np.array([28,26,30,30,26,28])*.8\n",
    "sequence3 = np.array([26,28,26,28,30,30])*.8\n",
    "\n",
    "plt.scatter([0,1,2,3,4,5],sequence3,marker='H',s=[200*(x-19) for x in sequence3],color='orange',alpha=.75,label='E0')\n",
    "plt.scatter([0,1,2,3,4,5],sequence2,marker='H',s=[200*(x-19) for x in sequence2],color='red',alpha=.8,label='E1')\n",
    "plt.scatter([0,1,2,3,4,5],sequence1,marker='H',s=[200*(x-19) for x in sequence1],color='black',label='E2')\n",
    "\n",
    "vals = []\n",
    "for triple in itertools.permutations(['E2','E1','E0']):\n",
    "    total = compare_values.apply(lambda x: 1 if x[triple[0]] >=  x[triple[1]] >= x[triple[2]] else 0,axis=1).sum()\n",
    "    compare_values[triple] = compare_values.apply(lambda x: 1 if x[triple[0]] >=  x[triple[1]] >= x[triple[2]] else 0,axis=1)\n",
    "    vals.append(total)\n",
    "\n",
    "\n",
    "plt.bar([0,1,2,3,4,5],[20 for i in range(6)],alpha=.075,color='gray')\n",
    "plt.plot([-.6,5.6],[compare_values[compare_values['sig']==1].sum()[3:-1].sum()/6,compare_values[compare_values['sig']==1].sum()[3:-1].sum()/6],color=(.1,.1,.1),alpha=.9,linestyle='dashed')\n",
    "plt.bar([0,1,2,3,4,5],compare_values.sum()[3:-1].values,color=(.8,.1,.15),alpha=.1,label='Removed')\n",
    "plt.bar([0,1,2,3,4,5],compare_values[compare_values['sig']==1].sum()[3:-1].values,color=(.1,.1,.15),alpha=.75)\n",
    "plt.grid(False)\n",
    "plt.xticks([0,1,2,3,4,5,7],['E: 2>1>0','E: 2>0>1','E: 1>2>0','E: 1>0>2','E: 0>2>1','E: 0>1>2',''])\n",
    "plt.yticks([0,5,10,15,20])\n",
    "plt.legend(loc='center right',prop={'size': 15})\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.chisquare(compare_values[compare_values['sig']>=0].sum()[3:-1].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.binom_test(20,29)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
